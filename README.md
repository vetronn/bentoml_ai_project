## AI Project ##

** setup pre Windows OS **
* spustenie Docker Desktop
* inÅ¡talÃ¡cia K3d (light version for K8s) in PowerShell
winget install k3d
winget install Kubernetes.kubectl
* install python 3.11 version + start in venv cez python lancher
cd project_dir
py -3.11 -m venv .venv
./.venv/Sript/Activate
* spustenie cluster s 2 nodemi a load balancerom 
k3d cluster create ml-lab
k3d cluster create ml-lab --agents 2 --port "8080:80@loadbalancer"
k3d cluster list

* natrenovanie modelu IRIS a uloÅ¾enie do model store
python train_and_save.py

* preverenie ci je model ulozeny
bentoml models list


### MODEL ###
Ako to funguje v praxi (Oddelenie vÃ¡h od kÃ³du)

V tvojom prÃ­pade uÅ¾ k oddeleniu dochÃ¡dza, len si to moÅ¾no neuvedomujeÅ¡, pretoÅ¾e sa to deje na tvojom disku:

    **Model Store (VÃ¡hy):** KeÄ spustÃ­Å¡ bentoml.sklearn.save_model(), BentoML vezme tie ÄistÃ© vÃ¡hy (binÃ¡rny sÃºbor) a uloÅ¾Ã­ ich do Å¡peciÃ¡lneho prieÄinka vo tvojom poÄÃ­taÄi (zvyÄajne v ~/bentoml/models/). KaÅ¾dÃ¡ verzia mÃ¡ svoj unikÃ¡tny tag (napr. housing_regressor:abc123xyz).

    **Service Code (Logika):** Tvoj service.py neobsahuje Å¾iadne vÃ¡hy. Obsahuje len inÅ¡trukciu: "ChoÄ do Model Store a vytiahni si odtiaÄ¾ najnovÅ¡iu verziu modelu s nÃ¡zvom housing_regressor".

**NOTE-PRODUCTION SCENARIO**
V tvojom sÃºÄasnom lokÃ¡lnom setup-e je "ÃºloÅ¾iskom vÃ¡h" tvoj disk. Ak by si vÅ¡ak pracoval v tÃ­me:

    VÃ¡hy by sa ukladali do S3 (AWS), Google Cloud Storage alebo BentoCloud.

    Tvoj Kubernetes cluster by si pri Å¡tarte kontajnera stiahol tieto vÃ¡hy z tohto cloudu.

### NEXT STEP ###
Tvoj ÄalÅ¡Ã­ krok v k3d

KeÄ urobÃ­Å¡ bentoml build, BentoML vykonÃ¡ "magickÃ© spojenie":

    *Zoberie tvoj kÃ³d (service.py).

    *Zoberie Å¡pecifickÃº verziu vÃ¡h z tvojho lokÃ¡lneho Model Store.

    *ZabalÃ­ ich spolu do jednÃ©ho Docker obrazu (tzv. Bento).

TÃ½mto mÃ¡Å¡ zaruÄenÃ©, Å¾e ten konkrÃ©tny kontajner mÃ¡ v sebe presne tie vÃ¡hy, s ktorÃ½mi bol otestovanÃ½.


*spustenie service
bentoml serve service.py:IrisService

*vytvorenie bentofile.yaml

Teraz premenÃ­me tvoj kÃ³d a model na jeden balÃ­k (Bento) a nÃ¡sledne na Docker image. Spusti tieto prÃ­kazy v terminÃ¡li:
*bentoml build
ÄŒo by sa stalo bez build?
Musel by si manuÃ¡lne pÃ­saÅ¥ Dockerfile, rieÅ¡iÅ¥, ako do kontajnera dostaÅ¥ tie binÃ¡rne vÃ¡hy modelu, a dÃ¡vaÅ¥ si pozor, aby si nezabudol na nejakÃº kniÅ¾nicu. BentoML to urobil za teba jednÃ½m prÃ­kazom.

*bentoml containerize iris_classifier:latest


###Nasadenie do k3d (Kubernetes)###

Aby tvoj lokÃ¡lny Kubernetes videl tento image, musÃ­me ho tam "vloÅ¾iÅ¥", pretoÅ¾e k3d nepouÅ¾Ã­va tvoj lokÃ¡lny Docker registry automaticky.

*import image to cluster
k3d image import iris_classifier:latest -c ml-lab
*run model in kubernetes
kubectl run iris-app --image=iris_classifier:3un6pmimi6a7hyep --port=3000 --image-pull-policy=Never
*expose port 
kubectl port-forward pod/iris-app 3000:3000


## MONITORING##
REVISION: 1
DESCRIPTION: Install complete
TEST SUITE: None
NOTES:
kube-prometheus-stack has been installed. Check its status by running:
  kubectl --namespace default get pods -l "release=monitoring"

Get Grafana 'admin' user password by running:

  kubectl --namespace default get secrets monitoring-grafana -o jsonpath="{.data.admin-password}" | base64 -d ; echo

  pre win
  $secret = kubectl get secret monitoring-grafana -o jsonpath="{.data.admin-password}" 
  [System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String($secret))


Access Grafana local instance:

  export POD_NAME=$(kubectl --namespace default get pod -l "app.kubernetes.io/name=grafana,app.kubernetes.io/instance=monitoring" -oname)
  kubectl --namespace default port-forward $POD_NAME 3000

Get your grafana admin user password by running:

  kubectl get secret --namespace default -l app.kubernetes.io/component=admin-secret -o jsonpath="{.items[0].data.admin-password}" | base64 --decode ; echo


  #Spustenie port-forward
  Start-Job -ScriptBlock { kubectl --namespace default port-forward monitoring-grafana-66c64d84c6-zglhw 3000:3000 }
  #zastavenie
  Get-Job
  Stop-Job -Name Job1  # Alebo pouÅ¾i ID, ktorÃ© uvidÃ­Å¡ v Get-Job



  ----------------------------------------------------------------

  Toto je kÄ¾ÃºÄovÃ¡ strategickÃ¡ otÃ¡zka pre tvoju kariÃ©ru. Ak sa chceÅ¡ staÅ¥ AI Platform Engineerom, odpoveÄ nie je â€jedno alebo druhÃ©â€œ, ale pochopenie ich poradia v produkÄnom reÅ¥azci.

Tu je rozbor toho, kam investovaÅ¥ Äas podÄ¾a tvojich cieÄ¾ov:
1. BentoML: Tvoj â€OperaÄnÃ½ systÃ©mâ€œ pre modely

BentoML by mal byÅ¥ tvojÃ­m vÃ½chodiskovÃ½m bodom. PreÄo? PretoÅ¾e rieÅ¡i logiku okolo modelu (tzv. "The Last Mile").

    ÄŒo sa nauÄÃ­Å¡: Ako vytvoriÅ¥ API, ako rieÅ¡iÅ¥ monitoring (Prometheus), ako baliÅ¥ kontajnery a ako orchestratovaÅ¥ pody v Kubernetes.

    Kedy ho pouÅ¾iÅ¥: VÅ¾dy, keÄ potrebujeÅ¡ nasadiÅ¥ klasickÃ© modely (ako Iris, XGBoost, Scikit-learn) alebo keÄ tvoj model vyÅ¾aduje zloÅ¾itÃ½ Python kÃ³d pred/po samotnom vÃ½poÄte (preprocessing).

2. vLLM a Triton: â€Motoryâ€œ pre extrÃ©mny vÃ½kon

Tieto nÃ¡stroje sÃº Å¡pecializovanÃ© komponenty, ktorÃ© v profesionÃ¡lnom prostredÃ­ Äasto beÅ¾ia pod BentoML alebo namiesto jeho Runnerov.

    vLLM: Je to krÃ¡Ä¾ dneÅ¡nej doby pre LLM (Llama, Mistral). Ak chceÅ¡ pracovaÅ¥ vo firme, ktorÃ¡ buduje vlastnÃ© chatboty, vLLM je dÃ´leÅ¾itejÅ¡ie neÅ¾ Triton, pretoÅ¾e rieÅ¡i Å¡pecifickÃ© problÃ©my pamÃ¤te u veÄ¾kÃ½ch modelov (PagedAttention).

    NVIDIA Triton: Je to priemyselnÃ½ Å¡tandard pre vÅ¡etko ostatnÃ© na GPU (poÄÃ­taÄovÃ© videnie, audio, video). Je to najkomplexnejÅ¡Ã­ nÃ¡stroj, ktorÃ½ ti dÃ¡va najvÃ¤ÄÅ¡iu kontrolu nad hardvÃ©rom.

ÄŒo sa uÄiÅ¥ a kedy? (Tvoj plÃ¡n rozvoja)

Ak chceÅ¡ pracovaÅ¥ â€profesionÃ¡lnejÅ¡ieâ€œ, postupuj v tÃ½chto vlnÃ¡ch:
ğŸŒŠ Vlna 1: OvlÃ¡dnutie platformy (BentoML + k3s)

    PreÄo: Tu sa nauÄÃ­Å¡ Kubernetes architektÃºru (pody, sluÅ¾by, ingress, monitorovanie). Bez tÃ½chto zÃ¡kladov ti bude Triton na niÄ, lebo ho nebudeÅ¡ vedieÅ¥ v klastri ani spustiÅ¥.

    Tvoj cieÄ¾: VedieÅ¥ nasadiÅ¥ model, ktorÃ½ sa sÃ¡m Å¡kÃ¡luje a mÃ¡ funkÄnÃ© grafy v Grafane.

ğŸŒŠ Vlna 2: Å pecializÃ¡cia na LLM (vLLM)

    PreÄo: LLM sÃº aktuÃ¡lne najÅ¾iadanejÅ¡ie.

    Tvoj cieÄ¾: IntegrovaÅ¥ vLLM do BentoML (ako Runner). NauÄÃ­Å¡ sa, ako uÅ¡etriÅ¥ firme tisÃ­ce eur optimalizÃ¡ciou GPU pamÃ¤te.

ğŸŒŠ Vlna 3: HardvÃ©rovÃ½ Expert (Triton)

    PreÄo: Triton je pre fajnÅ¡mekrov. Je to dopytovanÃ© v medicÃ­nskom videnÃ­, autonÃ³mnych autÃ¡ch alebo tam, kde zÃ¡leÅ¾Ã­ na kaÅ¾dej milisekunde.

    Tvoj cieÄ¾: NauÄiÅ¥ sa pÃ­saÅ¥ config.pbtxt a optimalizovaÅ¥ modely cez TensorRT.

Verdikt

Ak teraz rieÅ¡iÅ¡ Iris a k3d, zostaÅˆ hlbÅ¡ie pri BentoML. PrÃ¡ve na Åˆom sa nauÄÃ­Å¡ "Å¡pinavÃº prÃ¡cu" inÅ¾iniera (K8s YAML sÃºbory, Docker siete, monitoring), ktorÃ¡ je univerzÃ¡lna pre vÅ¡etky tri technolÃ³gie.

KeÄ budeÅ¡ v k3d suverÃ©nne ovlÃ¡daÅ¥ Deploymenty a ServiceMonitory, prechod na vLLM alebo Triton bude pre teba len vÃ½mena â€jednej sÃºÄiastky v strojiâ€œ.

Chcel by si, aby som ti ukÃ¡zal, ako v tvojom existujÃºcom BentoML kÃ³de vymeniÅ¥ ten klasickÃ½ Runner za vLLM Runner, aby si videl ten rozdiel v praxi?


-------------------------------------------------------------------------------------------------------


System validated with LOCUST at 500 concurrent users, maintaining <150ms latency through adaptive batching.

Pri zmene nastaveni BentoML pouzit pristup GitOps (nainstalovat ArgoCD)

## ARGOCD ##
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

#musia nabehnut sluzby
kubectl get pods -w -n argocd

#start UI
Start-Job -ScriptBlock{kubectl port-forward svc/argocd-server -n argocd 8080:443}

#obtain password
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | ForEach-Object { [System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String($_)) }
